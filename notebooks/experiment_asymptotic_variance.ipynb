{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a53d6f0",
   "metadata": {},
   "source": [
    "#### Simulate the asymptotic variance of different identification strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dcbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from identification_strategy_finder import AdjustmentSetFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de68952",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05075d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sandwich_covariance(X: np.ndarray, residuals: np.ndarray, I: np.ndarray, W: np.ndarray) -> np.ndarray:\n",
    "    n, k = X.shape\n",
    "    \n",
    "    Q_XI = np.dot(X.T, I) / n\n",
    "    Omega = np.zeros((I.shape[1], I.shape[1]))\n",
    "    for i in range(n):\n",
    "        Ii = I[i, :].reshape(-1, 1)\n",
    "        Omega += np.dot(Ii, Ii.T) * (residuals[i] ** 2)\n",
    "    Omega /= n\n",
    "    \n",
    "    Q_XI_W_Q_XI_T_inv = np.linalg.inv(np.dot(np.dot(Q_XI, W), Q_XI.T))\n",
    "    filling = np.dot(np.dot(Q_XI, W), np.dot(Omega, np.dot(W, Q_XI.T)))\n",
    "    \n",
    "    sandwich_cov = np.dot(Q_XI_W_Q_XI_T_inv, np.dot(filling, Q_XI_W_Q_XI_T_inv)) / n\n",
    "    return sandwich_cov\n",
    "\n",
    "def estimate_results(X, Y, G, n_samples, type_effect, hidden_nodes, one_suffices):\n",
    "    results_dict = {}\n",
    "    data, coefficients = simulate_linear_SCM(G, n_samples)\n",
    "    \n",
    "    adjustment_set_finder = AdjustmentSetFinder(G, X, Y, hidden_nodes, type_effect, one_suffices)\n",
    "    adjustment_sets = adjustment_set_finder.find_adjustment_sets_nuisance()\n",
    "\n",
    "    for i, item in enumerate(adjustment_sets):\n",
    "        I = list(item['Instrument Set']) if item['Instrument Set'] else None\n",
    "        B = list(item['Conditional Set']) if item['Conditional Set'] else None\n",
    "        if item['Nuisance Set']:\n",
    "            N = list(item['Nuisance Set'])\n",
    "        else:\n",
    "            N = None\n",
    "    \n",
    "        N_data = np.array(data.loc[:, N]) if N is not None else None\n",
    "        B_data = np.array(data.loc[:, B]) if B is not None else None\n",
    "        I_data = np.array(data.loc[:, I]) if I is not None else None\n",
    "        \n",
    "        X_data = np.array(data.loc[:, list(X)])\n",
    "        Y_data = np.array(data.loc[:, Y])\n",
    "        \n",
    "        result = civ(Y=Y_data, X=X_data, N=N_data, B=B_data, I=I_data)\n",
    "        \n",
    "        result_key = f\"N:{N}, B:{B}, I:{I}\"\n",
    "        results_dict[result_key] = {\n",
    "            'coefficients': result,\n",
    "            'adjustment_set': result_key\n",
    "        }\n",
    "        \n",
    "        if N_data is not None:\n",
    "            XN_data = np.hstack((X_data, N_data))\n",
    "        else:\n",
    "            XN_data = X_data\n",
    "        \n",
    "        residuals = Y_data.copy()\n",
    "        for j in range(XN_data.shape[1]):\n",
    "            residuals -= result[j] * XN_data[:, j]\n",
    "            \n",
    "        I_dim = I_data.shape[1]\n",
    "        \n",
    "        sandwich_cov = calculate_sandwich_covariance(XN_data, residuals, I_data, W = np.eye(I_dim))\n",
    "        standard_errors = np.sqrt(np.diag(sandwich_cov))\n",
    "        \n",
    "        results_dict[result_key]['standard_errors'] = standard_errors\n",
    "\n",
    "    if type_effect == \"total\":\n",
    "        total_causal_effect = 0\n",
    "        for node_x in X: \n",
    "            causal_paths_from_x_to_Y = list(nx.all_simple_paths(G, node_x, Y))\n",
    "            for path in causal_paths_from_x_to_Y:\n",
    "                path_coefficients = 1 \n",
    "\n",
    "                for i in range(len(path) - 1):\n",
    "                    edge = (path[i], path[i+1])\n",
    "                    edge_coefficient = coefficients[edge[1]][edge[0]] \n",
    "                    path_coefficients *= edge_coefficient    \n",
    "                total_causal_effect += path_coefficients\n",
    "            \n",
    "    best_results = {}\n",
    "    for i in range(len(list(X))):\n",
    "        min_se = float('inf')\n",
    "        best_key = None\n",
    "        for key, value in results_dict.items():\n",
    "            if value['standard_errors'][i] < min_se:\n",
    "                min_se = value['standard_errors'][i]\n",
    "                best_key = key\n",
    "        if best_key:\n",
    "            best_results[f'Best result for X_{i+1}'] = {\n",
    "                'coefficient': results_dict[best_key]['coefficients'][i],\n",
    "                'standard_error': results_dict[best_key]['standard_errors'][i],\n",
    "                'adjustment_set': results_dict[best_key]['adjustment_set']\n",
    "            }\n",
    "        \n",
    "    for key, value in results_dict.items():\n",
    "        print(f\"Adjustment Set: {key}\")\n",
    "        if type_effect == \"direct\":\n",
    "            print(f\"Population Coefficients: {coefficients[Y][list(X)[0]]}\")\n",
    "            \n",
    "        elif type_effect == \"total\":\n",
    "            print(f\"Population Coefficients: {total_causal_effect}\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid type_effect: must either be direct or total\")\n",
    "\n",
    "        if 'N:None' not in key:\n",
    "            n_number = key.split(\":\")[1].split(\",\")[0].strip(\"[]\")\n",
    "            if n_number != 'None':\n",
    "                if n_number.isdigit():\n",
    "                    n_column = int(n_number)\n",
    "                else:\n",
    "                    n_column = n_number.strip(\"'\") \n",
    "                    \n",
    "                if n_column in coefficients[Y]:\n",
    "                    print(f\"Nuisance Population Coefficients: {coefficients[Y][n_column]}\")\n",
    "                else:\n",
    "                    print(f\"Nuisance Population Coefficients: Column '{n_column}' has no direct effect on Y\")\n",
    "                \n",
    "        for i, coef in enumerate(value['coefficients'].flatten()):\n",
    "            print(f\"Coefficient {i+1}: {coef}\")\n",
    "            print(f\"Standard Error {i+1}: {value['standard_errors'][i]}\")\n",
    "        print()\n",
    "        \n",
    "    if not results_dict:\n",
    "        print(\"The effect is not identifiable, I am sorry!\")\n",
    "\n",
    "    return results_dict, coefficients, best_results\n",
    "\n",
    "\n",
    "def transform_strategy(strategy):\n",
    "    \"\"\"\n",
    "    Rename the strategies to make them fit for latex\n",
    "    \"\"\"\n",
    "    n_match = re.search(r'N:(\\[[^\\]]*\\]|None)', strategy)\n",
    "    b_match = re.search(r'B:\\[([^\\]]*)\\]', strategy)\n",
    "    i_match = re.search(r'I:\\[([^\\]]*)\\]', strategy)\n",
    "    \n",
    "    N = n_match.group(1) if n_match else 'None'\n",
    "    if N != 'None':\n",
    "        N = N.strip('[]').split(', ') if N.strip('[]') else []\n",
    "    else:\n",
    "        N = []\n",
    "    \n",
    "    B = b_match.group(1).split(', ') if b_match and b_match.group(1) else []\n",
    "    I = i_match.group(1).split(', ') if i_match and i_match.group(1) else []\n",
    "    \n",
    "    if not B:\n",
    "        B.append(r\"\\emptyset\")\n",
    "    if N:\n",
    "        civ = r\"$\\operatorname{CIV}(\" + ', '.join(I) + r\" \\mid X, \" + ', '.join(N) + r\" \\rightarrow Y \\mid \" + ', '.join(B) + r\")$\"\n",
    "    else:\n",
    "        civ = r\"$\\operatorname{CIV}(\" + ', '.join(I) + r\" \\mid X \\rightarrow Y \\mid \" + ', '.join(B) + r\")$\"\n",
    "    return civ\n",
    "\n",
    "\n",
    "def format_number(num):\n",
    "    \"\"\"\n",
    "    Add an apostroph to numbers to make them easy to read\n",
    "    \"\"\"\n",
    "    return f\"{int(num):,}\".replace(\",\", \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516c68f",
   "metadata": {},
   "source": [
    "#### Run the experiment for the specified graph\n",
    "Can easily be parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(1,2), (2,3), (4,2), (4,3), (4,5), (5,3),\n",
    "                  (6,1), (6,5), (6,2), (7,1), (8,3)])\n",
    "pos = {\n",
    "    1: (0,0),\n",
    "    2: (1,0),\n",
    "    3: (2,0),\n",
    "    4: (1.5,1),\n",
    "    5: (1,-0.5),\n",
    "    6: (0,-0.5),\n",
    "    7: (0,1),\n",
    "    8: (2,1)\n",
    "}\n",
    "nx.draw(G, pos = pos, with_labels = True)\n",
    "X = {2}\n",
    "Y = 3\n",
    "hidden_nodes = {4}\n",
    "\n",
    "sample_sizes = [20, 50, 200, 1000, 10000, 50000, 200000]\n",
    "num_seeds = 200\n",
    "\n",
    "coefficients = []\n",
    "standard_errors = []\n",
    "keys = []\n",
    "observations = []\n",
    "population_coefficients = []\n",
    "\n",
    "for seed in range(num_seeds):\n",
    "    np.random.seed(seed)  \n",
    "    for n in sample_sizes:\n",
    "        res, coefs, best = estimate_results(X=X, Y=Y, G=G, n_samples=n,\n",
    "                                            type_effect=\"total\",\n",
    "                                            hidden_nodes=hidden_nodes,\n",
    "                                            one_suffices=False)\n",
    "        for key, value in res.items():\n",
    "            keys.append(key)\n",
    "            coefficients.append(value[\"coefficients\"][0][0])\n",
    "            standard_errors.append(value[\"standard_errors\"][0])\n",
    "            observations.append(n)\n",
    "            population_coefficients.append(coefs[3][2])\n",
    "            \n",
    "results_df = pd.DataFrame({\n",
    "    \"strategy\": keys,\n",
    "    \"coefficient\": coefficients,\n",
    "    \"standard_error\": standard_errors,\n",
    "    \"n_samples\": observations,\n",
    "    \"population_coefficient\": population_coefficients})\n",
    "\n",
    "results_df.to_pickle(\"./results/asymptotic_variance_analysis.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13625b01",
   "metadata": {},
   "source": [
    "#### Process the data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_to_filter = [\n",
    "    \"N:[5], B:[1], I:[6, 7]\",\n",
    "    \"N:[5], B:[8, 1], I:[6, 7]\",\n",
    "    \"N:[5], B:None, I:[1, 7]\",\n",
    "    \"N:[5], B:[6], I:[1, 7]\",\n",
    "    \"N:[5], B:[8, 6], I:[1, 7]\",\n",
    "    \"N:[5], B:[8], I:[1, 7]\",\n",
    "    \"N:[8], B:[5, 6], I:[1, 7]\",\n",
    "    \"N:[8], B:[6], I:[1, 7]\",\n",
    "    \"N:[5, 8], B:None, I:[1, 6, 7]\"] # they violate the rank condition \n",
    "results_df = results_df[~results_df['strategy'].isin(strategies_to_filter)]\n",
    "\n",
    "average_se_df = results_df.groupby([\"strategy\", \"n_samples\"])[\"standard_error\"].mean().reset_index()\n",
    "results_df[\"coverage\"] = results_df.apply(lambda row: 1 if (row[\"population_coefficient\"] > row[\"coefficient\"] - 1.96 * row[\"standard_error\"] or row[\"population_coefficient\"] < row[\"coefficient\"] + 1.96 * row[\"standard_error\"] < row[\"population_coefficient\"]) else 0,axis=1)\n",
    "average_coverage_df = results_df.groupby([\"strategy\", \"n_samples\"])[\"coverage\"].mean().reset_index()\n",
    "\n",
    "average_se_df[\"n_samples\"] = average_se_df['n_samples'].apply(format_number)\n",
    "average_coverage_df[\"n_samples\"] = average_coverage_df[\"n_samples\"].apply(format_number)\n",
    "\n",
    "average_se_df[\"strategy\"] = average_se_df[\"strategy\"].apply(transform_strategy)\n",
    "average_coverage_df[\"strategy\"] = average_coverage_df[\"strategy\"].apply(transform_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173fb2eb",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Computer Modern Roman\"],\n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{amssymb}\",\n",
    "    \"axes.labelsize\": 22,     \n",
    "    \"xtick.labelsize\": 16,    \n",
    "    \"ytick.labelsize\": 18,    \n",
    "    \"legend.fontsize\": 14,    \n",
    "    \"figure.titlesize\": 22,   \n",
    "    \"axes.titlesize\": 2,\n",
    "    \"legend.title_fontsize\": 18})\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12), sharex=True)\n",
    "\n",
    "palette = sns.color_palette(\"coolwarm\", len(average_se_df[\"n_samples\"].unique()))\n",
    "sns.scatterplot(\n",
    "    data=average_se_df,\n",
    "    x=\"strategy\",\n",
    "    y=\"standard_error\",\n",
    "    hue=\"n_samples\",\n",
    "    palette=palette,\n",
    "    s=100,\n",
    "    ax=ax1\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.set_ylabel(\"Average standard error (log)\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.tick_params(labelbottom=False)  \n",
    "\n",
    "\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "ax1.legend(handles=handles, labels=labels, title=\"Sample size\", loc='upper center',\n",
    "           bbox_to_anchor=(0.25, 1.01), ncol=4, handletextpad=0.01, columnspacing=0.25)\n",
    "ax1.grid(which=\"major\", linestyle=\"--\", alpha=0.5, zorder=-1.0)\n",
    "plt.xticks(rotation=90, ha=\"center\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=average_coverage_df,\n",
    "    x=\"strategy\",\n",
    "    y=\"coverage\",\n",
    "    hue=\"n_samples\",\n",
    "    palette=palette,\n",
    "    s=100,\n",
    "    ax=ax2\n",
    ")\n",
    "\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.set_ylabel(r\"$\\widehat{\\mathbb{P}}(\\beta \\in \\operatorname{CI}_{\\alpha}(\\widehat{\\beta}))$\")\n",
    "ax2.legend(title=\"Sample size\", loc=3)\n",
    "ax2.grid(which=\"major\", linestyle=\"--\", alpha=0.5, zorder=-1.0)\n",
    "ax2.tick_params(labelbottom=True)  \n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "plt.savefig(\"./plots/combined_figure.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
